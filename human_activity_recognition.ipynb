{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNdTScrNphWC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!wget --no-check-certificate https://www.crcv.ucf.edu/data/UCF50.rar\n",
        "\n",
        "!unrar x UCF50.rar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8CKb2ndq0k8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install pafy youtube-dl moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okvLusjDrhSK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pafy\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from moviepy.editor import *\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical ,plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHlhFxOMs1Bn"
      },
      "outputs": [],
      "source": [
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHuc1RZIxjqe"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "all_classes_name = os.listdir('UCF50')\n",
        "\n",
        "random_range = random.sample(range(len(all_classes_name)) ,20)\n",
        "\n",
        "for counter ,random_index in enumerate(random_range ,1):\n",
        "\n",
        "   selected_class_name = all_classes_name[random_index]\n",
        "\n",
        "   video_files_names_list = os.listdir(f'UCF50/{selected_class_name}')\n",
        "\n",
        "   selected_video_file_name = random.choice(video_files_names_list)\n",
        "\n",
        "   video_reader = cv2.VideoCapture(f'UCF50/{selected_class_name}/{selected_video_file_name}')\n",
        "\n",
        "   _ ,bgr_frame = video_reader.read()\n",
        "\n",
        "   video_reader.release()\n",
        "\n",
        "   rgb_frame = cv2.cvtColor(bgr_frame ,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "   cv2.putText(rgb_frame ,selected_class_name ,(10,30) ,cv2.FONT_HERSHEY_SIMPLEX ,1 ,(255,255,255) ,2)\n",
        "\n",
        "   plt.subplot(5, 4, counter)\n",
        "   plt.imshow(rgb_frame)\n",
        "   plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JgWQhldyKTq"
      },
      "outputs": [],
      "source": [
        "IMAGE_HEIGHT ,IMAGE_WIDTH = 64 ,64\n",
        "\n",
        "SEQUENCE_LENGTH = 20\n",
        "\n",
        "DATASET_DIR = 'UCF50'\n",
        "\n",
        "CLASSES_LIST = ['Biking','PullUps','PushUps','Swing']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pCTNKPpyKQk"
      },
      "outputs": [],
      "source": [
        "def frame_extraction(video_path):\n",
        "\n",
        "    frames_list = []\n",
        "\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH) ,1)\n",
        "\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES ,frame_counter * skip_frames_window)\n",
        "\n",
        "        success ,frame = video_reader.read()\n",
        "\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        resized_frame = cv2.resize(frame ,(IMAGE_HEIGHT ,IMAGE_WIDTH))\n",
        "\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "    video_reader.release()\n",
        "\n",
        "    return frames_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uln93zOV3O40"
      },
      "outputs": [],
      "source": [
        "def create_dataset():\n",
        "\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_file_paths = []\n",
        "\n",
        "    for class_index ,class_name in enumerate(CLASSES_LIST):\n",
        "\n",
        "        print(f'Extracting Data of Class : {class_name}')\n",
        "\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR ,class_name))\n",
        "\n",
        "        for file_name in files_list:\n",
        "\n",
        "            video_file_path = os.path.join(DATASET_DIR ,class_name ,file_name)\n",
        "\n",
        "            frames = frame_extraction(video_file_path)\n",
        "\n",
        "            if len(frames)==SEQUENCE_LENGTH:\n",
        "\n",
        "                features.append(frames)\n",
        "                labels.append(class_index)\n",
        "                video_file_paths.append(video_file_path)\n",
        "\n",
        "    features = np.asarray(features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return features ,labels ,video_file_paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyPXfNYI593m"
      },
      "outputs": [],
      "source": [
        "features ,labels ,video_file_paths = create_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KOdBZ1q6v9x"
      },
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05ti0ALr6zQv"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZ3xsuMP6Ork"
      },
      "outputs": [],
      "source": [
        "one_hot_encoded_labels = to_categorical(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9ClEO6R6qUu"
      },
      "outputs": [],
      "source": [
        "one_hot_encoded_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQBtZU4t6t7r"
      },
      "outputs": [],
      "source": [
        "X_train , X_test ,Y_train ,Y_test = train_test_split(features ,one_hot_encoded_labels ,\n",
        "                                                     test_size=0.2 ,shuffle=True ,\n",
        "                                                     random_state=seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9xwbTfu7Yr_"
      },
      "outputs": [],
      "source": [
        "len(features) ,len(X_train) ,len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siSfVn5K7ea3"
      },
      "outputs": [],
      "source": [
        "def create_convlstm_model():\n",
        "\n",
        "    model = Sequential([\n",
        "\n",
        "        # layer 1\n",
        "        ConvLSTM2D(filters=4 ,kernel_size=(3,3) ,activation='tanh' ,data_format='channels_last' ,\n",
        "                  recurrent_dropout=0.2 ,return_sequences=True ,input_shape=(SEQUENCE_LENGTH ,IMAGE_HEIGHT ,IMAGE_WIDTH ,3)),\n",
        "\n",
        "        MaxPooling3D(pool_size=(1,2,2) ,padding='same' ,data_format='channels_last'),\n",
        "\n",
        "        TimeDistributed(Dropout(0.2)),\n",
        "\n",
        "        # layer 2\n",
        "        ConvLSTM2D(filters=8 ,kernel_size=(3,3) ,activation='tanh' ,data_format='channels_last' ,\n",
        "                  recurrent_dropout=0.2 ,return_sequences=True),\n",
        "\n",
        "        MaxPooling3D(pool_size=(1,2,2) ,padding='same' ,data_format='channels_last'),\n",
        "\n",
        "        TimeDistributed(Dropout(0.2)),\n",
        "\n",
        "        # layer 3\n",
        "        ConvLSTM2D(filters=14 ,kernel_size=(3,3) ,activation='tanh' ,data_format='channels_last' ,\n",
        "                  recurrent_dropout=0.2 ,return_sequences=True),\n",
        "\n",
        "        MaxPooling3D(pool_size=(1,2,2) ,padding='same' ,data_format='channels_last'),\n",
        "\n",
        "        TimeDistributed(Dropout(0.2)),\n",
        "\n",
        "        # layer 4\n",
        "        ConvLSTM2D(filters=16 ,kernel_size=(3,3) ,activation='tanh' ,data_format='channels_last' ,\n",
        "                  recurrent_dropout=0.2 ,return_sequences=True),\n",
        "\n",
        "        MaxPooling3D(pool_size=(1,2,2) ,padding='same' ,data_format='channels_last'),\n",
        "\n",
        "        # TimeDistributed(Dropout(0.2)),\n",
        "\n",
        "        Flatten(),\n",
        "\n",
        "        Dense(len(CLASSES_LIST) ,activation='softmax')\n",
        "\n",
        "    ])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEemhNm8_N0n"
      },
      "outputs": [],
      "source": [
        "convlstm_model = create_convlstm_model()\n",
        "convlstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWkm8gWs_8-G"
      },
      "outputs": [],
      "source": [
        "plot_model(convlstm_model ,to_file='convlstm_model_structure_plot.png' ,show_shapes=True ,show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drFOh-hNB2U0"
      },
      "outputs": [],
      "source": [
        "early_stoping_callbacks = EarlyStopping(monitor = 'val_loss' ,patience=10 ,mode = 'min' ,restore_best_weights = True)\n",
        "\n",
        "convlstm_model.compile(loss='categorical_crossentropy' ,optimizer='Adam' ,metrics=['accuracy'])\n",
        "\n",
        "convlstm_model_training_history = convlstm_model.fit( x=X_train , y=Y_train ,\n",
        "                                                     epochs=50 , batch_size=4 ,\n",
        "                                                      shuffle=True , validation_split=0.2 ,\n",
        "                                                      callbacks=[early_stoping_callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VksC0kJxDahg"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/convlstm_model.pickle','wb') as file:\n",
        "  pickle.dump(convlstm_model,file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XrJaEo2KGtg"
      },
      "outputs": [],
      "source": [
        "model_evalution_history = convlstm_model.evaluate(X_test ,Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiT0Xa3MLSG5"
      },
      "outputs": [],
      "source": [
        "model_evalution_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mea-EMyzLXC9"
      },
      "outputs": [],
      "source": [
        "convlstm_model_training_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbJDU1G7LbxW"
      },
      "outputs": [],
      "source": [
        "convlstm_model.save('convlstm_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPwVuMDUL0m4"
      },
      "outputs": [],
      "source": [
        "def plot_metric(model_training_history ,metric_name1 ,metric_name2 ,plot_name):\n",
        "\n",
        "  metric_value1 = model_training_history.history[metric_name1]\n",
        "  metric_value2 = model_training_history.history[metric_name2]\n",
        "\n",
        "  epochs = range(len(metric_value1))\n",
        "\n",
        "  plt.plot(epochs ,metric_value1 ,'blue' ,label=metric_name1)\n",
        "  plt.plot(epochs ,metric_value2 ,'red' ,label=metric_name2)\n",
        "\n",
        "  plt.title(str(plot_name))\n",
        "\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDl2TbqVN47K"
      },
      "outputs": [],
      "source": [
        "plot_metric(convlstm_model_training_history ,'loss' ,'val_loss' ,'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFmMDK4-OIm3"
      },
      "outputs": [],
      "source": [
        "plot_metric(convlstm_model_training_history ,'accuracy' ,'val_accuracy' ,'Total Accuracy vs Total Validation Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2e3gkwROwRX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1Hpyg4AT46x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmXZFR0uT6Hn"
      },
      "outputs": [],
      "source": [
        "def create_lrcn_model():\n",
        "\n",
        "    model = Sequential([\n",
        "\n",
        "        TimeDistributed(Conv2D(16 ,(3,3) ,padding='same' ,activation='relu'),\n",
        "                               input_shape=(SEQUENCE_LENGTH ,IMAGE_HEIGHT ,IMAGE_WIDTH ,3)),\n",
        "        TimeDistributed(MaxPooling2D((4,4))),\n",
        "        TimeDistributed(Dropout(0.2)),\n",
        "\n",
        "        TimeDistributed(Conv2D(32 ,(3,3) ,padding='same' ,activation='relu')),\n",
        "        TimeDistributed(MaxPooling2D((4,4))),\n",
        "        TimeDistributed(Dropout(0.2)),\n",
        "\n",
        "        TimeDistributed(Conv2D(64 ,(3,3) ,padding='same' ,activation='relu')),\n",
        "        TimeDistributed(MaxPooling2D((2,2))),\n",
        "        TimeDistributed(Dropout(0.2)),\n",
        "\n",
        "        TimeDistributed(Conv2D(64 ,(3,3) ,padding='same' ,activation='relu')),\n",
        "        TimeDistributed(MaxPooling2D((2,2))),\n",
        "        # TimeDistributed(Dropout(0.2)),\n",
        "\n",
        "        TimeDistributed(Flatten()),\n",
        "\n",
        "        Bidirectional(LSTM(32 ,return_sequences=True)),\n",
        "        Bidirectional(LSTM(64 ,return_sequences=True)),\n",
        "        Bidirectional(LSTM(64 ,return_sequences=False)),\n",
        "        # LSTM(32),\n",
        "\n",
        "        Dense(len(CLASSES_LIST) ,activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw9r4xm5WBX-"
      },
      "outputs": [],
      "source": [
        "lrcn_model = create_lrcn_model()\n",
        "lrcn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKIdkSxCWQI3"
      },
      "outputs": [],
      "source": [
        "plot_model(lrcn_model ,to_file='lrcn_model_structure_plot.png' ,show_shapes=True ,show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lht5Tfn8Yeqa"
      },
      "outputs": [],
      "source": [
        "early_stoping_callbacks = EarlyStopping(monitor = 'val_loss' ,patience=15 ,mode = 'min' ,restore_best_weights = True)\n",
        "\n",
        "lrcn_model.compile(loss='categorical_crossentropy' ,optimizer='Adam' ,metrics=['accuracy'])\n",
        "\n",
        "lrcn_model_training_history = lrcn_model.fit( x=X_train , y=Y_train ,\n",
        "                                                     epochs=70 , batch_size=4 ,\n",
        "                                                      shuffle=True , validation_split=0.2 ,\n",
        "                                                      callbacks=[early_stoping_callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXO9b8zTY9BI"
      },
      "outputs": [],
      "source": [
        "model_evalution_history = lrcn_model.evaluate(X_test ,Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hlE_MBsZRAA"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/lrcn_model.pickle','wb') as file:\n",
        "  pickle.dump(lrcn_model,file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqIvmX8wZfK6"
      },
      "outputs": [],
      "source": [
        "lrcn_model.save('lrcn_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5jL4EllZjUw"
      },
      "outputs": [],
      "source": [
        "plot_metric(lrcn_model_training_history ,'loss' ,'val_loss' ,'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d3dbFiLaZyN"
      },
      "outputs": [],
      "source": [
        "plot_metric(lrcn_model_training_history ,'accuracy' ,'val_accuracy' ,'Total Accuracy vs Total Validation Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZNuwyK_ajmK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVQq2lJabWTx"
      },
      "outputs": [],
      "source": [
        "def download_youtube_videos(youtube_video_url ,output_directory):\n",
        "\n",
        "    video = pafy.new(youtube_video_url)\n",
        "\n",
        "    title = video.title\n",
        "\n",
        "    video_best = video.getbest()\n",
        "\n",
        "    output_file_path = f'{output_directory}/{title}.mp4'\n",
        "\n",
        "    video_best.download(filepath = output_file_path ,quiet=True)\n",
        "\n",
        "    return title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDj4Q1kjcPHp"
      },
      "outputs": [],
      "source": [
        "# test_video_dir = 'test_videos'\n",
        "\n",
        "# os.makedirs(test_video_dir ,exist_ok =True)\n",
        "\n",
        "# video_title = download_youtube_videos('https://www.youtube.com/watch?v=aAggnpPyR6E',test_video_dir)\n",
        "\n",
        "# input_video_file_path = f'{test_video_dir}/{video_title}.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XCs7Pdcdg9L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-23 11:31:23.369808: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-23 11:31:23.369901: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-23 11:31:23.409103: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-23 11:31:23.494413: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-23 11:31:24.838131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "with open('models/lrcn_model.pickle' ,'rb') as file:\n",
        "    lrcn_model = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_69 (TimeD  (None, 20, 64, 64, 16)    448       \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_70 (TimeD  (None, 20, 16, 16, 16)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_71 (TimeD  (None, 20, 16, 16, 16)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_72 (TimeD  (None, 20, 16, 16, 32)    4640      \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_73 (TimeD  (None, 20, 4, 4, 32)      0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_74 (TimeD  (None, 20, 4, 4, 32)      0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_75 (TimeD  (None, 20, 4, 4, 64)      18496     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_76 (TimeD  (None, 20, 2, 2, 64)      0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_77 (TimeD  (None, 20, 2, 2, 64)      0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_78 (TimeD  (None, 20, 2, 2, 64)      36928     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_79 (TimeD  (None, 20, 1, 1, 64)      0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_80 (TimeD  (None, 20, 64)            0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirecti  (None, 20, 64)            24832     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirect  (None, 20, 128)           66048     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirect  (None, 128)               98816     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 250724 (979.39 KB)\n",
            "Trainable params: 250724 (979.39 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "lrcn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "SEQUENCE_LENGTH = 20\n",
        "IMAGE_HEIGHT ,IMAGE_WIDTH = 64 ,64\n",
        "CLASSES_LIST = ['Biking','PullUps','PushUps','Swing']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KyHg-RtKfXhX"
      },
      "outputs": [],
      "source": [
        "\n",
        "def predict_on_single_action(video_path):\n",
        "        frame_deque = deque(maxlen=SEQUENCE_LENGTH)\n",
        "\n",
        "        video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "        video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH) ,1)\n",
        "\n",
        "        for frame_counter in range(SEQUENCE_LENGTH):\n",
        "\n",
        "            video_reader.set(cv2.CAP_PROP_POS_FRAMES ,frame_counter * skip_frames_window)\n",
        "\n",
        "            success ,frame = video_reader.read()\n",
        "\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            resized_frame = cv2.resize(frame ,(IMAGE_HEIGHT ,IMAGE_WIDTH))\n",
        "\n",
        "            normalized_frame = resized_frame / 255\n",
        "\n",
        "            frame_deque.append(normalized_frame)\n",
        "\n",
        "        video_reader.release()\n",
        "\n",
        "        predicted_probs = lrcn_model.predict(np.expand_dims(frame_deque ,axis=0))[0]\n",
        "\n",
        "        predicted_label =  np.argmax(predicted_probs)\n",
        "\n",
        "        predicted_class_name = CLASSES_LIST[predicted_label]\n",
        "\n",
        "        print(predicted_class_name ,predicted_probs[predicted_label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Biking 0.97140527\n"
          ]
        }
      ],
      "source": [
        "predict_on_single_action('test_video.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n"
          ]
        }
      ],
      "source": [
        "import imageio\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "\n",
        "def predict_on_multiple_actions(video_path, output_path, SEQUENCE_LENGTH):\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "    \n",
        "    video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    \n",
        "    video_writer = imageio.get_writer(output_path + '.mp4', fps=video_reader.get(cv2.CAP_PROP_FPS))\n",
        "    \n",
        "    frame_deque = deque(maxlen=SEQUENCE_LENGTH)\n",
        "    predicted_class_name = ''\n",
        "\n",
        "    while video_reader.isOpened():\n",
        "        success, frame = video_reader.read()\n",
        "\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "        normalized_frame = resized_frame / 255\n",
        "        frame_deque.append(normalized_frame)\n",
        "\n",
        "        if len(frame_deque) == SEQUENCE_LENGTH:\n",
        "            predicted_probs = lrcn_model.predict(np.expand_dims(frame_deque, axis=0))[0]\n",
        "            predicted_label = np.argmax(predicted_probs)\n",
        "            predicted_class_name = CLASSES_LIST[predicted_label]\n",
        "\n",
        "        cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        video_writer.append_data(frame)\n",
        "\n",
        "    video_reader.release()\n",
        "    video_writer.close()\n",
        "\n",
        "predict_on_multiple_actions('test_video.mp4', 'output_video', SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_single_action(video_path ,SEQUENCE_LENGTH):\n",
        "    \n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "    \n",
        "    video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    \n",
        "    frames_list = []\n",
        "    \n",
        "    predicted_class_name = ''\n",
        "    \n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH) ,1)\n",
        "\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES ,frame_counter * skip_frames_window)\n",
        "\n",
        "        success ,frame = video_reader.read()\n",
        "\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        resized_frame = cv2.resize(frame ,(IMAGE_HEIGHT ,IMAGE_WIDTH))\n",
        "\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "    predicted_probs = lrcn_model.predict(np.expand_dims(frame_deque ,axis=0))[0]\n",
        "\n",
        "    predicted_label =  np.argmax(predicted_probs)\n",
        "\n",
        "    predicted_class_name = CLASSES_LIST[predicted_label]\n",
        "    \n",
        "    print(predicted_class_name ,predicted_probs[predicted_label])\n",
        "    \n",
        "    video_reader.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "PullUps 0.99910563\n"
          ]
        }
      ],
      "source": [
        "predict_single_action('test_video.mp4' ,SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def cut_video(input_path, output_path, start_time, end_time):\n",
        "    \"\"\"\n",
        "    Cut (trim) a video based on specified start and end times.\n",
        "\n",
        "    Parameters:\n",
        "        - input_path (str): Path to the input video file.\n",
        "        - output_path (str): Path to the output (trimmed) video file.\n",
        "        - start_time (float): Start time in seconds.\n",
        "        - end_time (float): End time in seconds.\n",
        "    \"\"\"\n",
        "\n",
        "    # Open the video file\n",
        "    video_capture = cv2.VideoCapture(input_path)\n",
        "\n",
        "    # Get the frames per second (fps) and total number of frames\n",
        "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate start and end frame numbers based on start_time and end_time\n",
        "    start_frame = int(start_time * fps)\n",
        "    end_frame = int(end_time * fps)\n",
        "\n",
        "    # Ensure the end_frame is within the total_frames\n",
        "    end_frame = min(end_frame, total_frames - 1)\n",
        "\n",
        "    # Set the starting frame position\n",
        "    video_capture.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "    # Create VideoWriter object to write the trimmed video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Adjust the codec as needed\n",
        "    video_writer = cv2.VideoWriter(output_path, fourcc, fps, (int(video_capture.get(3)), int(video_capture.get(4))))\n",
        "\n",
        "    # Read and write frames within the specified range\n",
        "    for frame_counter in range(start_frame, end_frame + 1):\n",
        "        success, frame = video_capture.read()\n",
        "        if not success:\n",
        "            break\n",
        "        video_writer.write(frame)\n",
        "\n",
        "    # Release video capture and writer objects\n",
        "    video_capture.release()\n",
        "    video_writer.release()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_video_path = 'biking.mp4'\n",
        "    output_video_path = 'test_video.mp4'\n",
        "    start_time_seconds = 3  # Specify start time in seconds\n",
        "    end_time_seconds = 7    # Specify end time in seconds\n",
        "\n",
        "    cut_video(input_video_path, output_video_path, start_time_seconds, end_time_seconds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
